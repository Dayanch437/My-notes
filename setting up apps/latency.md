Latency refers to the time delay between the initiation of an action and the occurrence of its effect. In different contexts, latency can have specific meanings:

1. **Networking**: In networking, latency is the time it takes for a data packet to travel from the source to the destination. It is often measured in milliseconds (ms) and can be influenced by factors such as distance, network congestion, and the quality of the connection.
    
2. **Computing**: In computing, latency can refer to the delay between a user's action and the response from the system. For example, the time it takes for a computer to process a command and display the result.
    
3. **Audio/Video**: In audio and video streaming, latency is the delay between the moment a signal is sent and when it is received or played back. High latency can cause synchronization issues, such as audio being out of sync with video.
    
4. **Human-Computer Interaction**: In this context, latency refers to the delay between a user's input (like a mouse click or keystroke) and the system's response. Low latency is crucial for a smooth user experience, especially in real-time applications like gaming or virtual reality.
    
5. **Storage**: In storage systems, latency is the time it takes for a data request to be fulfilled, from the moment it is initiated to the moment the data is retrieved.